{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Explore and create ML datasets </h1>\n",
    "\n",
    "このノートブックでは、New Yorkでのタクシー乗車に関するデータを探索し、乗車料金を予測する機械学習モデルを作成いたします。<br>\n",
    "タクシー料金を予測する目的は、乗車後に請求に驚いたりしないように、また予想よりずっと高額な請求をされたときに抗議することができるようにすることです。\n",
    "\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "では、必要なPythonライブラリのimportから始めていきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> BigQueryからサンプルデータを取得する</h3>\n",
    "\n",
    "\n",
    "これから私達が利用するデータセットは<a href=\"https://bigquery.cloud.google.com/table/nyc-tlc:yellow.trips\">BigQueryのpublic dataset</a>です。リンクをクリックして、カラム名をチェックしましょう。<br>\n",
    "[Detail]タブに移動してレコード数が10億行あることを確認し、[Preview]タブでいくつかのデータを確認してみてください。\n",
    "\n",
    "\n",
    "では、SQLを書いていくつかのフィールドをピックアップしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "  SELECT\n",
    "    pickup_datetime, pickup_longitude, pickup_latitude, dropoff_longitude,\n",
    "    dropoff_latitude, passenger_count, trip_distance, tolls_amount, \n",
    "    fare_amount, total_amount \n",
    "  FROM `nyc-tlc.yellow.trips`\n",
    "  LIMIT 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "trips = client.query(sql).to_dataframe()\n",
    "trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レコード数を増やして、きれいなグラフを書いてみましょう。返されるレコードの順番は保証されないため、LIMITの数を増やしてもどのレコードが返ってくるかはわかりません。<br>\n",
    "適切にデータセットを取得するために、乗車時刻のHASHを利用して10万行に1行だけを取得しましょう。つまり、10億行のデータがあれば、およそ1万行のデータが取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "  SELECT\n",
    "    pickup_datetime,\n",
    "    pickup_longitude, pickup_latitude, \n",
    "    dropoff_longitude, dropoff_latitude,\n",
    "    passenger_count,\n",
    "    trip_distance,\n",
    "    tolls_amount,\n",
    "    fare_amount,\n",
    "    total_amount\n",
    "  FROM\n",
    "    `nyc-tlc.yellow.trips`\n",
    "  WHERE\n",
    "    MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), 100000) = 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = client.query(sql).to_dataframe()\n",
    "trips[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> データを探索する</h3>\n",
    "\n",
    "では、データを探索し、必要に応じてクリーンアップをしていきましょう。ここでは、PythonのSeabornパッケージを利用してグラフをビジュアライズし、Pandasを使ってスライシングとフィルタリングを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x=\"trip_distance\", y=\"fare_amount\", fit_reg=False, ci=None, truncate=True, data=trips)\n",
    "ax.figure.set_size_inches(10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なにかおかしな点があることに気づきますか？\n",
    "\n",
    "どうやら、乗車距離が0であったり、乗車料金が明らかに非合法であったりなどの無効なデータがたくさんあるようです。<br>\n",
    "これらは分析対象から除外しましょう。BigQueryへのクエリを変更して、乗車距離が0マイル以上かつ、乗車料金が最低乗車料金（$2.50）以上のデータに絞り込むことができます。\n",
    "\n",
    "追加されたWHERE句に注目してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "  SELECT\n",
    "    pickup_datetime,\n",
    "    pickup_longitude, pickup_latitude, \n",
    "    dropoff_longitude, dropoff_latitude,\n",
    "    passenger_count,\n",
    "    trip_distance,\n",
    "    tolls_amount,\n",
    "    fare_amount,\n",
    "    total_amount\n",
    "  FROM\n",
    "    `nyc-tlc.yellow.trips`\n",
    "  WHERE\n",
    "    MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), 100000) = 1\n",
    "    AND trip_distance > 0 AND fare_amount >= 2.5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = client.query(sql).to_dataframe()\n",
    "ax = sns.regplot(x=\"trip_distance\", y=\"fare_amount\", fit_reg=False, ci=None, truncate=True, data=trips)\n",
    "ax.figure.set_size_inches(10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45ドル、50ドル付近の直線は何でしょうか？これは、たとえばマンハッタンのJFK空港、La Guardia空港からの定額料金と予測できます。\n",
    "データを確認して、値が何を意味しているのかを確認してみましょう。\n",
    "\n",
    "toll_amount（定額料金）とtotal_amount（総額料金）の関係に注目してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tollrides = trips[trips['tolls_amount'] > 0]\n",
    "tollrides[tollrides['pickup_datetime'] == pd.Timestamp('2010-04-29 12:28:00', tz = 'UTC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のいくつかのサンプルデータを見てみると、総額料金(total_amount)は乗車料金(fare_amount)と定額料金(tolls_amount）を反映していることは明らかです。そして任意のチップが加えられていますが、チップを現金で支払った場合にはチップの値段はわかりません。\n",
    "そのため、ここではfare_amount + tolls_amountを予測の対象として利用します。チップは乗客の裁量によるため、料金予測ツールからは除外するべきでしょう。\n",
    "\n",
    "では、カラムごとの値の分布を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どうやら経度(longitude)と緯度(latitude)の最小値と最大値がおかしいようです。\n",
    "\n",
    "いくつかの履歴の乗車(pickup)位置と降車(dropoff)位置を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showrides(df, numlines):\n",
    "  lats = []\n",
    "  lons = []\n",
    "  for iter, row in df[:numlines].iterrows():\n",
    "    lons.append(row['pickup_longitude'])\n",
    "    lons.append(row['dropoff_longitude'])\n",
    "    lons.append(None)\n",
    "    lats.append(row['pickup_latitude'])\n",
    "    lats.append(row['dropoff_latitude'])\n",
    "    lats.append(None)\n",
    "\n",
    "  sns.set_style(\"darkgrid\")\n",
    "  plt.figure(figsize=(10,8))\n",
    "  plt.plot(lons, lats)\n",
    "\n",
    "showrides(trips, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showrides(tollrides, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予想したとおり、定額料金を含む乗車は他の典型的な乗車よりも距離が長いようです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> データクレンジングとその他の前処理</h3>\n",
    "\n",
    "以下のデータクレンジングが必要です。\n",
    "\n",
    "<ol>\n",
    "<li>New Yorkの経度は-74前後、緯度は41前後</li>\n",
    "<li>乗客が0人のデータは含めない</li>\n",
    "<li>総額料金(total_amount)を、乗車料金(fare_amount)と定額料金(tolls_amount)だけを反映するようにする。またこれら２つの列は除外する</li>\n",
    "<li>乗車時には、乗車位置と降車位置はわかっていますが、乗車距離はわかりません（乗車距離はルートによって変わるため）。そのため乗車距離は機械学習のデータセットには含めない</li>\n",
    "<li>タイムスタンプを削除する</li>\n",
    "</ol>\n",
    "\n",
    "距離0の乗車を除外したのと同様にBigQueryを使って前処理を行うことができますが、他の方法をお見せするためにここではPythonを使いましょう。<br>\n",
    "本番環境では、リアルタイムの入力データに対して同様の前処理を行う必要があります。（Dataflowなどを利用する）\n",
    "\n",
    "入力データに対するこのような前処理は、機械学習を行う際に一般的です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(trips_in):\n",
    "  trips = trips_in.copy(deep=True)\n",
    "  trips.fare_amount = trips.fare_amount + trips.tolls_amount\n",
    "  del trips['tolls_amount']\n",
    "  del trips['total_amount']\n",
    "  del trips['trip_distance']\n",
    "  del trips['pickup_datetime']\n",
    "  qc = np.all([\\\n",
    "             trips['pickup_longitude'] > -78, \\\n",
    "             trips['pickup_longitude'] < -70, \\\n",
    "             trips['dropoff_longitude'] > -78, \\\n",
    "             trips['dropoff_longitude'] < -70, \\\n",
    "             trips['pickup_latitude'] > 37, \\\n",
    "             trips['pickup_latitude'] < 45, \\\n",
    "             trips['dropoff_latitude'] > 37, \\\n",
    "             trips['dropoff_latitude'] < 45, \\\n",
    "             trips['passenger_count'] > 0,\n",
    "            ], axis=0)\n",
    "  return trips[qc]\n",
    "\n",
    "tripsqc = preprocess(trips)\n",
    "tripsqc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データクレンジングにより、およそ300行(11400 - 11101)、全体の3％ほどのデータが除外されました。これは良いバランスです。\n",
    "\n",
    "では、機械学習用データセットを作成しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 機械学習用データセットの作成 </h3>\n",
    "\n",
    "クレンジングされたデータを学習用と検証用、テスト用のデータセットにランダムに分割しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = tripsqc.sample(frac=1)\n",
    "trainsize = int(len(shuffled['fare_amount']) * 0.70)\n",
    "validsize = int(len(shuffled['fare_amount']) * 0.15)\n",
    "\n",
    "df_train = shuffled.iloc[:trainsize, :]\n",
    "df_valid = shuffled.iloc[trainsize:(trainsize+validsize), :]\n",
    "df_test = shuffled.iloc[(trainsize+validsize):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3つのDataframeをcsvファイルに書き出しましょう。<br>\n",
    "DataflowやCloud MLを利用できるようになるまでは、ローカルでのトレーニングにこれらのファイルを使用します（これらのファイルは全データの内の1/100000件のデータのみを含むということを思い出してください）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(df, filename):\n",
    "  outdf = df.copy(deep=False)\n",
    "  outdf.loc[:, 'key'] = np.arange(0, len(outdf)) # rownumber as key\n",
    "  # reorder columns so that target is first column\n",
    "  cols = outdf.columns.tolist()\n",
    "  cols.remove('fare_amount')\n",
    "  cols.insert(0, 'fare_amount')\n",
    "  print (cols)  # new order of columns\n",
    "  outdf = outdf[cols]\n",
    "  outdf.to_csv(filename, header=False, index_label=False, index=False)\n",
    "\n",
    "to_csv(df_train, 'taxi-train.csv')\n",
    "to_csv(df_valid, 'taxi-valid.csv')\n",
    "to_csv(df_test, 'taxi-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 taxi-valid.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> データセットが存在することを確認する </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習、検証、テストに対応する３つのcsvファイルが作成されました。ファイルサイズの割合はデータの分割の割合に対応しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head taxi-train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上手くいっていますね！機械学習用のデータセットが作成され、機械学習モデルのトレーニング、検証、評価の準備ができました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ベンチマーク </h3>\n",
    "\n",
    "複雑な機械学習モデルを作成するまえに、簡単なモデルを作成してそれをベンチマークとするのは良いアイデアです。\n",
    "\n",
    "以下のモデルは、総額料金(fare_amount)の平均を乗車距離(trip_distance)で割り、距離毎の料金の割合を計算します。<br>\n",
    "これを用いてRMSEを算出してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between(lat1, lon1, lat2, lon2):\n",
    "  # haversine formula to compute distance \"as the crow flies\".  Taxis can't fly of course.\n",
    "  dist = np.degrees(np.arccos(np.minimum(1,np.sin(np.radians(lat1)) * np.sin(np.radians(lat2)) + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.cos(np.radians(lon2 - lon1))))) * 60 * 1.515 * 1.609344\n",
    "  return dist\n",
    "\n",
    "def estimate_distance(df):\n",
    "  return distance_between(df['pickuplat'], df['pickuplon'], df['dropofflat'], df['dropofflon'])\n",
    "\n",
    "def compute_rmse(actual, predicted):\n",
    "  return np.sqrt(np.mean((actual-predicted)**2))\n",
    "\n",
    "def print_rmse(df, rate, name):\n",
    "  print (\"{1} RMSE = {0}\".format(compute_rmse(df['fare_amount'], rate*estimate_distance(df)), name))\n",
    "\n",
    "FEATURES = ['pickuplon','pickuplat','dropofflon','dropofflat','passengers']\n",
    "TARGET = 'fare_amount'\n",
    "columns = list([TARGET])\n",
    "columns.extend(FEATURES) # in CSV, target is the first column, after the features\n",
    "columns.append('key')\n",
    "df_train = pd.read_csv('taxi-train.csv', header=None, names=columns)\n",
    "df_valid = pd.read_csv('taxi-valid.csv', header=None, names=columns)\n",
    "df_test = pd.read_csv('taxi-test.csv', header=None, names=columns)\n",
    "rate = df_train['fare_amount'].mean() / estimate_distance(df_train).mean()\n",
    "print (\"Rate = ${0}/km\".format(rate))\n",
    "print_rmse(df_train, rate, 'Train')\n",
    "print_rmse(df_valid, rate, 'Valid') \n",
    "print_rmse(df_test, rate, 'Test') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>同じデータセットのベンチマーク</h2>\n",
    "\n",
    "RMSEはデータセットに依存するため、比較のために同じデータセットを評価に利用します。<br>\n",
    "以下のクエリーは後のラボでも使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1=train 2=valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "SELECT\n",
    "  (tolls_amount + fare_amount) AS fare_amount,\n",
    "  CONCAT(CAST(pickup_datetime AS STRING), CAST(pickup_longitude AS STRING), CAST(pickup_latitude AS STRING), CAST(dropoff_latitude AS STRING), CAST(dropoff_longitude AS STRING)) AS key,\n",
    "  EXTRACT(DAYOFWEEK FROM pickup_datetime)*1.0 AS dayofweek,\n",
    "  EXTRACT(HOUR FROM pickup_datetime)*1.0 AS hourofday,\n",
    "  pickup_longitude AS pickuplon,\n",
    "  pickup_latitude AS pickuplat,\n",
    "  dropoff_longitude AS dropofflon,\n",
    "  dropoff_latitude AS dropofflat,\n",
    "  passenger_count*1.0 AS passengers\n",
    "FROM\n",
    "  `nyc-tlc.yellow.trips`\n",
    "WHERE\n",
    "  trip_distance > 0\n",
    "  AND fare_amount >= 2.5\n",
    "  AND pickup_longitude > -78\n",
    "  AND pickup_longitude < -70\n",
    "  AND dropoff_longitude > -78\n",
    "  AND dropoff_longitude < -70\n",
    "  AND pickup_latitude > 37\n",
    "  AND pickup_latitude < 45\n",
    "  AND dropoff_latitude > 37\n",
    "  AND dropoff_latitude < 45\n",
    "  AND passenger_count > 0\n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # training\n",
    "      query = \"{0} AND MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), 4) < 2\".format(base_query)\n",
    "    else:\n",
    "      query = \"{0} AND MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), 4) = {1}\".format(base_query, phase)\n",
    "  else:\n",
    "      query = \"{0} AND MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), {1}) = {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "\n",
    "query = create_query(2, 100000)\n",
    "df_valid = client.query(query).to_dataframe()\n",
    "print_rmse(df_valid, 2.56, 'Final Validation Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "簡単な距離ベースのルールではRMSEが<b>7.42ドル</b>です。もちろん、この値を超えなければなりませんが、このような簡単なルールを超えるのは驚くほど難しいものです。\n",
    "\n",
    "しかし、まずは野心的に、テストデータで6ドル以下のRMSEとなる機械学習モデルを作成することを目指していきましょう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2016 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
